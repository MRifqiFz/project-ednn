{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchmetrics.functional.classification import *\n",
    "from skorch import NeuralNetClassifier\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, InputSpec\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from skmultilearn.ext import Keras\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X24  X25  X26  Y1  Y2  Y3  \\\n",
       "0   3   1   1   1   1   1   1   1   3    1  ...    1    3    1   2   2   1   \n",
       "1   5   3   1   1   2   4   2   1   5    1  ...    1    2    2   2   2   2   \n",
       "2   4   1   1   1   2   1   2   2   2    2  ...    2    3    1   2   2   2   \n",
       "3   4   1   1   1   2   4   2   1   1    1  ...    2    3    2   2   2   2   \n",
       "4   2   1   1   3   1   3   1   1   1    1  ...    1    3    1   2   2   2   \n",
       "\n",
       "   Y4  Y5  Y6  Y7  \n",
       "0   2   2   1   2  \n",
       "1   2   2   1   1  \n",
       "2   2   2   2   1  \n",
       "3   1   2   1   2  \n",
       "4   2   2   2   2  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:\\Project\\project-ednn\\Code\\Final_dataset_Diabetes_Complication.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>X26</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543770</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543771</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543772</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543773</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543774</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543775 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        X1  X2  X3  X4  X5  X6  X7  X8  X9  X10  ...  X24  X25  X26  Y1  Y2  \\\n",
       "0        3   1   1   1   1   1   1   1   3    1  ...    1    3    1   2   2   \n",
       "1        5   3   1   1   2   4   2   1   5    1  ...    1    2    2   2   2   \n",
       "2        4   1   1   1   2   1   2   2   2    2  ...    2    3    1   2   2   \n",
       "3        4   1   1   1   2   4   2   1   1    1  ...    2    3    2   2   2   \n",
       "4        2   1   1   3   1   3   1   1   1    1  ...    1    3    1   2   2   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ..  ..   \n",
       "543770   1   1   2   1   1   4   1   1   5    2  ...    2    3    1   2   2   \n",
       "543771   2   1   1   1   1   4   1   1   5    1  ...    1    2    2   2   2   \n",
       "543772   1   2   1   1   1   3   1   1   2    1  ...    1    3    1   2   2   \n",
       "543773   3   1   2   1   1   3   1   1   2    2  ...    1    3    2   2   2   \n",
       "543774   1   1   1   1   1   4   1   1   2    1  ...    1    3    2   2   2   \n",
       "\n",
       "        Y3  Y4  Y5  Y6  Y7  \n",
       "0        1   2   2   1   2  \n",
       "1        2   2   2   1   1  \n",
       "2        2   2   2   2   1  \n",
       "3        2   1   2   1   2  \n",
       "4        2   2   2   2   2  \n",
       "...     ..  ..  ..  ..  ..  \n",
       "543770   2   2   2   2   2  \n",
       "543771   1   2   2   2   1  \n",
       "543772   2   2   2   2   1  \n",
       "543773   2   2   1   2   2  \n",
       "543774   2   2   2   2   2  \n",
       "\n",
       "[543775 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 543775 entries, 0 to 543774\n",
      "Data columns (total 33 columns):\n",
      " #   Column  Non-Null Count   Dtype\n",
      "---  ------  --------------   -----\n",
      " 0   X1      543775 non-null  int64\n",
      " 1   X2      543775 non-null  int64\n",
      " 2   X3      543775 non-null  int64\n",
      " 3   X4      543775 non-null  int64\n",
      " 4   X5      543775 non-null  int64\n",
      " 5   X6      543775 non-null  int64\n",
      " 6   X7      543775 non-null  int64\n",
      " 7   X8      543775 non-null  int64\n",
      " 8   X9      543775 non-null  int64\n",
      " 9   X10     543775 non-null  int64\n",
      " 10  X11     543775 non-null  int64\n",
      " 11  X12     543775 non-null  int64\n",
      " 12  X13     543775 non-null  int64\n",
      " 13  X14     543775 non-null  int64\n",
      " 14  X15     543775 non-null  int64\n",
      " 15  X16     543775 non-null  int64\n",
      " 16  X17     543775 non-null  int64\n",
      " 17  X18     543775 non-null  int64\n",
      " 18  X19     543775 non-null  int64\n",
      " 19  X20     543775 non-null  int64\n",
      " 20  X21     543775 non-null  int64\n",
      " 21  X22     543775 non-null  int64\n",
      " 22  X23     543775 non-null  int64\n",
      " 23  X24     543775 non-null  int64\n",
      " 24  X25     543775 non-null  int64\n",
      " 25  X26     543775 non-null  int64\n",
      " 26  Y1      543775 non-null  int64\n",
      " 27  Y2      543775 non-null  int64\n",
      " 28  Y3      543775 non-null  int64\n",
      " 29  Y4      543775 non-null  int64\n",
      " 30  Y5      543775 non-null  int64\n",
      " 31  Y6      543775 non-null  int64\n",
      " 32  Y7      543775 non-null  int64\n",
      "dtypes: int64(33)\n",
      "memory usage: 136.9 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "      <th>Y5</th>\n",
       "      <th>Y6</th>\n",
       "      <th>Y7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543770</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543771</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543772</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543773</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543774</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>543775 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Y1  Y2  Y3  Y4  Y5  Y6  Y7\n",
       "0        2   2   1   2   2   1   2\n",
       "1        2   2   2   2   2   1   1\n",
       "2        2   2   2   2   2   2   1\n",
       "3        2   2   2   1   2   1   2\n",
       "4        2   2   2   2   2   2   2\n",
       "...     ..  ..  ..  ..  ..  ..  ..\n",
       "543770   2   2   2   2   2   2   2\n",
       "543771   2   2   1   2   2   2   1\n",
       "543772   2   2   2   2   2   2   1\n",
       "543773   2   2   2   2   1   2   2\n",
       "543774   2   2   2   2   2   2   2\n",
       "\n",
       "[543775 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_feature = data.iloc[:, :26]\n",
    "data_label = data.iloc[:, 26:]\n",
    "data_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the DataFrame to obtain the normalized data\n",
    "data_normalized = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_normalized[:, :26]\n",
    "y = data_normalized[:, 26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalize = pd.DataFrame(scaler.transform(data), columns=data.columns)\n",
    "df_feature = data_normalize.iloc[:, :26]\n",
    "df_label = data_normalize.iloc[:, 26:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "for i, label in enumerate(df_label.columns):\n",
    "    values_1 = df_label[label][df_label[label] == 1]\n",
    "    values_2 = df_label[label][df_label[label] == 2]\n",
    "    dist = 1 - (len(values_1) / len(df_label))\n",
    "    weight_list.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0483, 0.0652, 0.0605, 0.0508, 0.1008, 0.3895, 0.4290],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_ = torch.Tensor(weight_list).to(device)\n",
    "weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            # print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModelwithWeightedDropout(tf.keras.Model):\n",
    "    def __init__(self, num_features=26, num_classes=7, p=[0.05, 0.01, 0.003]):\n",
    "        super(DNNModelwithWeightedDropout, self).__init__()\n",
    "        self.fcn1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(32, activation='relu', input_shape=(num_features,)),\n",
    "            tf.keras.layers.Dense(len(p), activation='softmax')\n",
    "        ])\n",
    "        self.dropout = [tf.keras.layers.Dropout(rate=rate) for rate in p]\n",
    "        self.fcn2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=None, mask=None):\n",
    "        x = self.fcn1(x)\n",
    "        weights = x\n",
    "\n",
    "        # Apply weighted dropout\n",
    "        x = [dropout(x[:, i], training=training) * weights[:, i] for i, dropout in enumerate(self.dropout)]\n",
    "\n",
    "        x = tf.stack(x, axis=1)\n",
    "        x = self.fcn2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNDropout(tf.keras.Model):\n",
    "    def __init__(self, num_features=26, num_classes=7, p=0.5):\n",
    "        super(DNNDropout, self).__init__()\n",
    "\n",
    "        self.fcn1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(16, activation='relu'),\n",
    "            tf.keras.layers.Dense(8, activation='relu'),\n",
    "            tf.keras.layers.Dense(3, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(p)\n",
    "\n",
    "        self.fcn2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.fcn1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fcn2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropoutModel(n_inputs, n_outputs, dropout_rate=0.3):\n",
    "    model = DNNDropout(num_features=n_inputs, num_classes=n_outputs, p=dropout_rate)\n",
    "    lossWeights = weight_list\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.003), metrics=['accuracy'], loss_weights=lossWeights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProposedModel1(n_inputs, n_outputs, dropout_rate=[0.3]*3):\n",
    "    model = DNNModelwithWeightedDropout(num_features=n_inputs, num_classes=n_outputs, p=dropout_rate)\n",
    "    lossWeights = weight_list\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.003), metrics=['accuracy'], loss_weights=lossWeights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_list = [0.1, 0.2, 0.3, 0.5, 0.7, 0.9]\n",
    "channel_list = [3, 6, 8, 16, 32, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0156 - accuracy: 0.3380 - val_loss: 0.0149 - val_accuracy: 0.2240\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0153 - accuracy: 0.2994 - val_loss: 0.0148 - val_accuracy: 0.3229\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0153 - accuracy: 0.2970 - val_loss: 0.0149 - val_accuracy: 0.4424\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0153 - accuracy: 0.3032 - val_loss: 0.0149 - val_accuracy: 0.2613\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0153 - accuracy: 0.2992 - val_loss: 0.0149 - val_accuracy: 0.3566\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0153 - accuracy: 0.3044 - val_loss: 0.0149 - val_accuracy: 0.1592\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0153 - accuracy: 0.3099 - val_loss: 0.0149 - val_accuracy: 0.3170\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 51s 4ms/step - loss: 0.0153 - accuracy: 0.3220 - val_loss: 0.0149 - val_accuracy: 0.2934\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0153 - accuracy: 0.2939 - val_loss: 0.0149 - val_accuracy: 0.3427\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0153 - accuracy: 0.2951 - val_loss: 0.0149 - val_accuracy: 0.4175\n",
      "Base Model: 529.9992227554321\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0157 - accuracy: 0.3701 - val_loss: 0.0150 - val_accuracy: 0.3149\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0153 - accuracy: 0.3528 - val_loss: 0.0149 - val_accuracy: 0.2808\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0152 - accuracy: 0.3412 - val_loss: 0.0149 - val_accuracy: 0.2040\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0152 - accuracy: 0.3260 - val_loss: 0.0148 - val_accuracy: 0.2695\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0152 - accuracy: 0.3353 - val_loss: 0.0149 - val_accuracy: 0.2207\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0152 - accuracy: 0.3337 - val_loss: 0.0149 - val_accuracy: 0.3263\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0152 - accuracy: 0.3275 - val_loss: 0.0149 - val_accuracy: 0.3923\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0153 - accuracy: 0.3353 - val_loss: 0.0149 - val_accuracy: 0.3167\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0152 - accuracy: 0.3280 - val_loss: 0.0149 - val_accuracy: 0.3273\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0153 - accuracy: 0.3284 - val_loss: 0.0149 - val_accuracy: 0.2777\n",
      "Proposed Model: 553.0587403774261\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0159 - accuracy: 0.3409 - val_loss: 0.0152 - val_accuracy: 0.3691\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0156 - accuracy: 0.3507 - val_loss: 0.0152 - val_accuracy: 0.2926\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0156 - accuracy: 0.3471 - val_loss: 0.0152 - val_accuracy: 0.3275\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0156 - accuracy: 0.3524 - val_loss: 0.0151 - val_accuracy: 0.3934\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0156 - accuracy: 0.3549 - val_loss: 0.0152 - val_accuracy: 0.3143\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0156 - accuracy: 0.3486 - val_loss: 0.0152 - val_accuracy: 0.3838\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0156 - accuracy: 0.3539 - val_loss: 0.0152 - val_accuracy: 0.4334\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0156 - accuracy: 0.3604 - val_loss: 0.0152 - val_accuracy: 0.3904\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0156 - accuracy: 0.3681 - val_loss: 0.0152 - val_accuracy: 0.2815\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0156 - accuracy: 0.3546 - val_loss: 0.0151 - val_accuracy: 0.3934\n",
      "Base Model: 539.1550989151001\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0159 - accuracy: 0.4236 - val_loss: 0.0151 - val_accuracy: 0.2456\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0156 - accuracy: 0.4010 - val_loss: 0.0151 - val_accuracy: 0.4418\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0155 - accuracy: 0.3738 - val_loss: 0.0151 - val_accuracy: 0.2636\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0155 - accuracy: 0.3515 - val_loss: 0.0151 - val_accuracy: 0.3352\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0155 - accuracy: 0.3614 - val_loss: 0.0151 - val_accuracy: 0.2628\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0155 - accuracy: 0.3406 - val_loss: 0.0151 - val_accuracy: 0.3633\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 59s 4ms/step - loss: 0.0155 - accuracy: 0.3558 - val_loss: 0.0150 - val_accuracy: 0.2719\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0155 - accuracy: 0.3490 - val_loss: 0.0151 - val_accuracy: 0.3147\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0155 - accuracy: 0.3504 - val_loss: 0.0151 - val_accuracy: 0.3489\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0155 - accuracy: 0.3613 - val_loss: 0.0151 - val_accuracy: 0.2867\n",
      "Proposed Model: 558.7908432483673\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0162 - accuracy: 0.3763 - val_loss: 0.0154 - val_accuracy: 0.2722\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3993 - val_loss: 0.0154 - val_accuracy: 0.0072\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 51s 4ms/step - loss: 0.0159 - accuracy: 0.3825 - val_loss: 0.0154 - val_accuracy: 0.2240\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3866 - val_loss: 0.0154 - val_accuracy: 0.3936\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3931 - val_loss: 0.0154 - val_accuracy: 0.2947\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3926 - val_loss: 0.0153 - val_accuracy: 0.2483\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 51s 4ms/step - loss: 0.0159 - accuracy: 0.3969 - val_loss: 0.0153 - val_accuracy: 0.4752\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3867 - val_loss: 0.0154 - val_accuracy: 0.5017\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.4145 - val_loss: 0.0154 - val_accuracy: 0.2643\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0159 - accuracy: 0.3951 - val_loss: 0.0154 - val_accuracy: 0.3596\n",
      "Base Model: 518.6720790863037\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0162 - accuracy: 0.4028 - val_loss: 0.0154 - val_accuracy: 0.4244\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.4388 - val_loss: 0.0152 - val_accuracy: 0.3752\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3796 - val_loss: 0.0153 - val_accuracy: 0.3236\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.3876 - val_loss: 0.0153 - val_accuracy: 0.4346\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0158 - accuracy: 0.3876 - val_loss: 0.0153 - val_accuracy: 0.2122\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 58s 4ms/step - loss: 0.0158 - accuracy: 0.3927 - val_loss: 0.0153 - val_accuracy: 0.3742\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3899 - val_loss: 0.0153 - val_accuracy: 0.4018\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0158 - accuracy: 0.3970 - val_loss: 0.0153 - val_accuracy: 0.4103\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.3897 - val_loss: 0.0152 - val_accuracy: 0.3484\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.3977 - val_loss: 0.0153 - val_accuracy: 0.3703\n",
      "Proposed Model: 551.8222615718842\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0166 - accuracy: 0.4923 - val_loss: 0.0158 - val_accuracy: 0.2701\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4800 - val_loss: 0.0157 - val_accuracy: 0.2678\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4859 - val_loss: 0.0157 - val_accuracy: 0.3901\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4989 - val_loss: 0.0159 - val_accuracy: 0.5603\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.5022 - val_loss: 0.0158 - val_accuracy: 0.2838\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4895 - val_loss: 0.0158 - val_accuracy: 0.5629\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4898 - val_loss: 0.0157 - val_accuracy: 0.5054\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4945 - val_loss: 0.0157 - val_accuracy: 0.3292\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0164 - accuracy: 0.4889 - val_loss: 0.0158 - val_accuracy: 0.3296\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0164 - accuracy: 0.4962 - val_loss: 0.0158 - val_accuracy: 0.5153\n",
      "Base Model: 521.5665285587311\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0167 - accuracy: 0.5165 - val_loss: 0.0156 - val_accuracy: 0.4061\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0162 - accuracy: 0.4785 - val_loss: 0.0155 - val_accuracy: 0.4113\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4659 - val_loss: 0.0156 - val_accuracy: 0.2978\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4848 - val_loss: 0.0156 - val_accuracy: 0.4242\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4749 - val_loss: 0.0156 - val_accuracy: 0.3872\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4669 - val_loss: 0.0156 - val_accuracy: 0.2548\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0163 - accuracy: 0.4680 - val_loss: 0.0156 - val_accuracy: 0.4013\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4692 - val_loss: 0.0156 - val_accuracy: 0.4169\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0163 - accuracy: 0.4702 - val_loss: 0.0156 - val_accuracy: 0.4237\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0163 - accuracy: 0.4808 - val_loss: 0.0156 - val_accuracy: 0.3523\n",
      "Proposed Model: 554.4851500988007\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0171 - accuracy: 0.5935 - val_loss: 0.0163 - val_accuracy: 0.4301\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6112 - val_loss: 0.0162 - val_accuracy: 0.0042\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0169 - accuracy: 0.6077 - val_loss: 0.0162 - val_accuracy: 0.3849\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0169 - accuracy: 0.6129 - val_loss: 0.0163 - val_accuracy: 0.4249\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6190 - val_loss: 0.0164 - val_accuracy: 0.4827\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6057 - val_loss: 0.0163 - val_accuracy: 0.4200\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.5841 - val_loss: 0.0160 - val_accuracy: 0.4555\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6119 - val_loss: 0.0163 - val_accuracy: 0.5215\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6163 - val_loss: 0.0162 - val_accuracy: 0.0042\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0169 - accuracy: 0.6189 - val_loss: 0.0162 - val_accuracy: 0.4462\n",
      "Base Model: 523.4267365932465\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0171 - accuracy: 0.6842 - val_loss: 0.0161 - val_accuracy: 0.4308\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0168 - accuracy: 0.6968 - val_loss: 0.0160 - val_accuracy: 0.3008\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0168 - accuracy: 0.6667 - val_loss: 0.0161 - val_accuracy: 0.4326\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0168 - accuracy: 0.6398 - val_loss: 0.0162 - val_accuracy: 0.4551\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0168 - accuracy: 0.6470 - val_loss: 0.0161 - val_accuracy: 0.2938\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0168 - accuracy: 0.6003 - val_loss: 0.0160 - val_accuracy: 0.5294\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0168 - accuracy: 0.6482 - val_loss: 0.0161 - val_accuracy: 0.4695\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0168 - accuracy: 0.6856 - val_loss: 0.0160 - val_accuracy: 0.4410\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0168 - accuracy: 0.6313 - val_loss: 0.0162 - val_accuracy: 0.6322\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0168 - accuracy: 0.6249 - val_loss: 0.0160 - val_accuracy: 0.4361\n",
      "Proposed Model: 545.8183982372284\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 53s 4ms/step - loss: 0.0177 - accuracy: 0.6988 - val_loss: 0.0169 - val_accuracy: 0.5982\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7728 - val_loss: 0.0168 - val_accuracy: 0.3263\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7621 - val_loss: 0.0170 - val_accuracy: 0.9203\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.6941 - val_loss: 0.0167 - val_accuracy: 0.5474\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7423 - val_loss: 0.0169 - val_accuracy: 0.9073\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7876 - val_loss: 0.0169 - val_accuracy: 0.8823\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7309 - val_loss: 0.0168 - val_accuracy: 0.8210\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7805 - val_loss: 0.0169 - val_accuracy: 0.7555\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7163 - val_loss: 0.0169 - val_accuracy: 0.0040\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 52s 4ms/step - loss: 0.0174 - accuracy: 0.7686 - val_loss: 0.0170 - val_accuracy: 0.7803\n",
      "Base Model: 520.8167719841003\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0176 - accuracy: 0.7580 - val_loss: 0.0169 - val_accuracy: 0.5789\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0173 - accuracy: 0.7621 - val_loss: 0.0169 - val_accuracy: 0.7183\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 57s 4ms/step - loss: 0.0173 - accuracy: 0.7726 - val_loss: 0.0171 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0174 - accuracy: 0.7523 - val_loss: 0.0168 - val_accuracy: 0.5198\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0174 - accuracy: 0.7302 - val_loss: 0.0171 - val_accuracy: 0.8738\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0174 - accuracy: 0.7535 - val_loss: 0.0169 - val_accuracy: 0.9419\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 58s 4ms/step - loss: 0.0174 - accuracy: 0.7401 - val_loss: 0.0170 - val_accuracy: 0.4103\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0174 - accuracy: 0.7617 - val_loss: 0.0170 - val_accuracy: 0.8344\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0174 - accuracy: 0.7742 - val_loss: 0.0169 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0174 - accuracy: 0.7257 - val_loss: 0.0169 - val_accuracy: 0.7494\n",
      "Proposed Model: 557.4469616413116\n"
     ]
    }
   ],
   "source": [
    "for i in dropout_list:\n",
    "    base = DropoutModel(26, 7, dropout_rate=i)\n",
    "    prop = ProposedModel1(26, 7, dropout_rate=[i]*3)\n",
    "\n",
    "    csv_logger = tf.keras.callbacks.CSVLogger(f'./HyperparameterResults/base_dropout{i}.csv', append=True, separator=',')\n",
    "    csv_logger2 = tf.keras.callbacks.CSVLogger(f'./HyperparameterResults/prop_dropout{i}.csv', append=True, separator=',')\n",
    "\n",
    "    base_init = time.time()\n",
    "    base.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32, verbose=1, callbacks=[csv_logger])\n",
    "    base_time = time.time() - base_init\n",
    "    print(f'Base Model: {base_time}')\n",
    "    \n",
    "    prop_init = time.time()\n",
    "    prop.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32, verbose=1, callbacks=[csv_logger2])\n",
    "    prop_time = time.time() - prop_init\n",
    "    print(f'Proposed Model: {prop_time}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0162 - accuracy: 0.4131 - val_loss: 0.0154 - val_accuracy: 0.4010\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3954 - val_loss: 0.0153 - val_accuracy: 0.3836\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3977 - val_loss: 0.0152 - val_accuracy: 0.1828\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3954 - val_loss: 0.0153 - val_accuracy: 0.2931\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.3810 - val_loss: 0.0153 - val_accuracy: 0.4091\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0158 - accuracy: 0.3872 - val_loss: 0.0154 - val_accuracy: 0.3351\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 56s 4ms/step - loss: 0.0158 - accuracy: 0.3950 - val_loss: 0.0153 - val_accuracy: 0.3770\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 55s 4ms/step - loss: 0.0158 - accuracy: 0.4038 - val_loss: 0.0152 - val_accuracy: 0.2676\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.3936 - val_loss: 0.0153 - val_accuracy: 0.3655\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 54s 4ms/step - loss: 0.0158 - accuracy: 0.3943 - val_loss: 0.0153 - val_accuracy: 0.1866\n",
      "Proposed Model: 549.6999247074127\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 66s 5ms/step - loss: 0.0160 - accuracy: 0.4697 - val_loss: 0.0150 - val_accuracy: 0.5298\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 64s 5ms/step - loss: 0.0154 - accuracy: 0.3960 - val_loss: 0.0149 - val_accuracy: 0.2947\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 64s 5ms/step - loss: 0.0154 - accuracy: 0.3653 - val_loss: 0.0148 - val_accuracy: 0.3227\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0153 - accuracy: 0.3717 - val_loss: 0.0148 - val_accuracy: 0.4077\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 65s 5ms/step - loss: 0.0153 - accuracy: 0.3842 - val_loss: 0.0149 - val_accuracy: 0.3155\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0153 - accuracy: 0.3494 - val_loss: 0.0149 - val_accuracy: 0.3663\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0154 - accuracy: 0.3654 - val_loss: 0.0149 - val_accuracy: 0.4056\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0154 - accuracy: 0.3554 - val_loss: 0.0149 - val_accuracy: 0.4127\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0154 - accuracy: 0.3481 - val_loss: 0.0149 - val_accuracy: 0.2966\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 62s 5ms/step - loss: 0.0154 - accuracy: 0.3403 - val_loss: 0.0149 - val_accuracy: 0.2842\n",
      "Proposed Model: 630.5317153930664\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0160 - accuracy: 0.4013 - val_loss: 0.0149 - val_accuracy: 0.2033\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0154 - accuracy: 0.3778 - val_loss: 0.0149 - val_accuracy: 0.1775\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0153 - accuracy: 0.3667 - val_loss: 0.0148 - val_accuracy: 0.3106\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0153 - accuracy: 0.3671 - val_loss: 0.0148 - val_accuracy: 0.3870\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0152 - accuracy: 0.3549 - val_loss: 0.0148 - val_accuracy: 0.3134\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0152 - accuracy: 0.3392 - val_loss: 0.0149 - val_accuracy: 0.4284\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 71s 5ms/step - loss: 0.0152 - accuracy: 0.3173 - val_loss: 0.0148 - val_accuracy: 0.4135\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0152 - accuracy: 0.3296 - val_loss: 0.0149 - val_accuracy: 0.3994\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0152 - accuracy: 0.3314 - val_loss: 0.0149 - val_accuracy: 0.2665\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 70s 5ms/step - loss: 0.0153 - accuracy: 0.3205 - val_loss: 0.0148 - val_accuracy: 0.3275\n",
      "Proposed Model: 702.1464319229126\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 79s 6ms/step - loss: 0.0161 - accuracy: 0.4555 - val_loss: 0.0150 - val_accuracy: 0.4459\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0154 - accuracy: 0.3939 - val_loss: 0.0149 - val_accuracy: 0.1516\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 79s 6ms/step - loss: 0.0153 - accuracy: 0.3875 - val_loss: 0.0149 - val_accuracy: 0.2217\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3627 - val_loss: 0.0148 - val_accuracy: 0.2634\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3515 - val_loss: 0.0148 - val_accuracy: 0.3147\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3327 - val_loss: 0.0148 - val_accuracy: 0.3538\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3253 - val_loss: 0.0148 - val_accuracy: 0.1506\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3142 - val_loss: 0.0148 - val_accuracy: 0.2838\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.3115 - val_loss: 0.0148 - val_accuracy: 0.1687\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 78s 6ms/step - loss: 0.0152 - accuracy: 0.2991 - val_loss: 0.0148 - val_accuracy: 0.3256\n",
      "Proposed Model: 782.2599802017212\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 108s 8ms/step - loss: 0.0161 - accuracy: 0.4551 - val_loss: 0.0151 - val_accuracy: 0.2171\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 106s 8ms/step - loss: 0.0155 - accuracy: 0.4160 - val_loss: 0.0149 - val_accuracy: 0.2188\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 105s 8ms/step - loss: 0.0153 - accuracy: 0.3692 - val_loss: 0.0148 - val_accuracy: 0.4928\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 105s 8ms/step - loss: 0.0152 - accuracy: 0.3568 - val_loss: 0.0148 - val_accuracy: 0.1467\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 105s 8ms/step - loss: 0.0152 - accuracy: 0.3393 - val_loss: 0.0148 - val_accuracy: 0.1502\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 105s 8ms/step - loss: 0.0152 - accuracy: 0.3273 - val_loss: 0.0147 - val_accuracy: 0.2971\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 107s 8ms/step - loss: 0.0152 - accuracy: 0.3423 - val_loss: 0.0148 - val_accuracy: 0.3821\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 107s 8ms/step - loss: 0.0151 - accuracy: 0.3326 - val_loss: 0.0148 - val_accuracy: 0.3651\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 108s 8ms/step - loss: 0.0151 - accuracy: 0.3307 - val_loss: 0.0148 - val_accuracy: 0.3606\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 108s 8ms/step - loss: 0.0151 - accuracy: 0.3283 - val_loss: 0.0148 - val_accuracy: 0.3814\n",
      "Proposed Model: 1065.6421065330505\n",
      "Epoch 1/10\n",
      "13595/13595 [==============================] - 169s 12ms/step - loss: 0.0161 - accuracy: 0.4624 - val_loss: 0.0151 - val_accuracy: 0.4472\n",
      "Epoch 2/10\n",
      "13595/13595 [==============================] - 163s 12ms/step - loss: 0.0155 - accuracy: 0.3748 - val_loss: 0.0149 - val_accuracy: 0.3176\n",
      "Epoch 3/10\n",
      "13595/13595 [==============================] - 164s 12ms/step - loss: 0.0154 - accuracy: 0.3654 - val_loss: 0.0148 - val_accuracy: 0.1639\n",
      "Epoch 4/10\n",
      "13595/13595 [==============================] - 164s 12ms/step - loss: 0.0153 - accuracy: 0.3433 - val_loss: 0.0149 - val_accuracy: 0.4017\n",
      "Epoch 5/10\n",
      "13595/13595 [==============================] - 162s 12ms/step - loss: 0.0152 - accuracy: 0.3634 - val_loss: 0.0148 - val_accuracy: 0.3936\n",
      "Epoch 6/10\n",
      "13595/13595 [==============================] - 160s 12ms/step - loss: 0.0152 - accuracy: 0.3666 - val_loss: 0.0149 - val_accuracy: 0.3581\n",
      "Epoch 7/10\n",
      "13595/13595 [==============================] - 160s 12ms/step - loss: 0.0152 - accuracy: 0.3293 - val_loss: 0.0148 - val_accuracy: 0.3295\n",
      "Epoch 8/10\n",
      "13595/13595 [==============================] - 160s 12ms/step - loss: 0.0152 - accuracy: 0.3149 - val_loss: 0.0148 - val_accuracy: 0.3506\n",
      "Epoch 9/10\n",
      "13595/13595 [==============================] - 160s 12ms/step - loss: 0.0152 - accuracy: 0.3184 - val_loss: 0.0148 - val_accuracy: 0.2141\n",
      "Epoch 10/10\n",
      "13595/13595 [==============================] - 161s 12ms/step - loss: 0.0152 - accuracy: 0.3018 - val_loss: 0.0148 - val_accuracy: 0.2779\n",
      "Proposed Model: 1622.5707635879517\n"
     ]
    }
   ],
   "source": [
    "for i in channel_list:\n",
    "    prop = ProposedModel1(26, 7, dropout_rate=[0.3]*i)\n",
    "\n",
    "    csv_logger2 = tf.keras.callbacks.CSVLogger(f'./HyperparameterResults/prop_channel{i}.csv', append=True, separator=',')\n",
    "    \n",
    "    prop_init = time.time()\n",
    "    prop.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32, verbose=1, callbacks=[csv_logger2])\n",
    "    prop_time = time.time() - prop_init\n",
    "    print(f'Proposed Model: {prop_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
