{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchmetrics.functional.classification import binary_accuracy, binary_auroc, binary_f1_score, binary_precision, binary_recall\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Dropout, InputSpec\n",
    "from keras.utils import *\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "    ca  thal  num  \n",
       "0  0.0   6.0    0  \n",
       "1  3.0   3.0    2  \n",
       "2  2.0   7.0    1  \n",
       "3  0.0   3.0    0  \n",
       "4  0.0   3.0    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart_disease_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(ignore_index=True)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    float64\n",
      " 12  thal      303 non-null    float64\n",
      " 13  num       303 non-null    int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "4     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "4    119\n",
       "2    104\n",
       "3     97\n",
       "1     69\n",
       "0     39\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine = SMOTEENN()\n",
    "X_combine, y_combine = combine.fit_resample(data.drop('num', axis=1), data['num'])\n",
    "y_combine.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Program Files\\Anaconda\\envs\\py310\\lib\\site-packages\\threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_smote, y_smote = smote.fit_resample(data.drop('num', axis=1), data['num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    164\n",
       "4    164\n",
       "1     55\n",
       "2     36\n",
       "3     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create an instance of OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "# One-hot encode the 'num' column\n",
    "onehot_encoded = onehot_encoder.fit_transform(data[['num']]).toarray()\n",
    "\n",
    "onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data)\n",
    "\n",
    "# Transform the DataFrame to obtain the normalized data\n",
    "data_normalized = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_normalized[:, :-1]\n",
    "y = data_normalized[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.5 , 0.25, 0.  , 0.  , 0.  , 0.75, 0.  , 0.5 , 0.25, 0.  ,\n",
       "       0.  , 0.5 , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.25, 0.75, 1.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.5 , 0.25,\n",
       "       0.  , 0.  , 0.  , 0.75, 0.25, 0.75, 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "       0.25, 1.  , 0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.25,\n",
       "       0.25, 0.25, 0.25, 0.  , 0.  , 0.5 , 0.  , 0.25, 0.  , 0.5 , 0.5 ,\n",
       "       0.25, 0.  , 0.5 , 0.25, 0.  , 0.75, 0.25, 0.25, 0.25, 0.  , 0.25,\n",
       "       0.  , 0.  , 0.75, 0.  , 0.  , 0.  , 0.75, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.75, 0.  , 0.  , 0.  , 0.25, 0.5 , 0.75, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.5 , 0.25, 0.5 , 0.75,\n",
       "       0.25, 0.25, 0.  , 0.5 , 0.5 , 0.  , 0.  , 0.  , 0.75, 0.5 , 0.75,\n",
       "       1.  , 0.  , 0.75, 0.25, 0.  , 0.75, 0.75, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 1.  , 0.75, 0.25, 0.  , 0.  , 0.25, 0.  ,\n",
       "       0.25, 0.  , 0.25, 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ,\n",
       "       0.75, 0.25, 0.25, 0.25, 0.5 , 0.  , 0.  , 1.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.25, 0.  , 0.75, 0.  , 0.25, 0.  , 1.  , 0.25,\n",
       "       0.  , 0.25, 0.  , 0.  , 0.75, 0.5 , 0.  , 0.  , 0.25, 0.  , 0.  ,\n",
       "       0.5 , 0.25, 0.5 , 0.  , 0.75, 0.25, 0.5 , 0.  , 0.75, 0.  , 0.  ,\n",
       "       0.  , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.75, 0.75, 0.  ,\n",
       "       0.25, 0.  , 1.  , 0.  , 0.75, 0.25, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.75, 0.25, 0.  , 0.  , 0.  , 0.75, 0.5 , 0.  ,\n",
       "       0.5 , 0.25, 0.  , 0.  , 0.75, 0.5 , 0.25, 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.5 , 0.  , 0.5 , 0.5 , 0.25, 0.75, 0.  , 0.  , 0.25, 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.75, 0.  , 0.  ,\n",
       "       1.  , 0.5 , 0.5 , 0.5 , 0.25, 0.  , 0.25, 0.  , 0.5 , 0.  , 0.25,\n",
       "       0.  , 0.  , 0.  , 0.25, 0.  , 0.5 , 0.  , 0.75, 0.  , 0.5 , 1.  ,\n",
       "       0.5 , 0.  , 0.  , 0.  , 0.25, 0.  , 0.5 , 0.5 , 0.25, 0.  , 0.75,\n",
       "       0.25, 0.25, 0.5 , 0.75, 0.25, 0.  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = onehot_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelWeightedDropout(tf.keras.Model):\n",
    "    def __init__(self, out, p=0.5):\n",
    "        super(MultiChannelWeightedDropout, self).__init__()\n",
    "\n",
    "        self.in_layer = tf.keras.layers.Dense(3, activation='softmax')\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(p)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(p)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(p)\n",
    "\n",
    "        self.out_layer = tf.keras.layers.Dense(out, activation='sigmoid')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.in_layer(x)\n",
    "        weights = x\n",
    "\n",
    "        # Apply weighted dropout\n",
    "        channel1 = self.dropout1(x[:, 0], training=training) * weights[:, 0]\n",
    "        channel2 = self.dropout2(x[:, 1], training=training) * weights[:, 1]\n",
    "        channel3 = self.dropout3(x[:, 2], training=training) * weights[:, 2]\n",
    "\n",
    "        x = tf.stack([channel1, channel2, channel3], axis=1)\n",
    "        x = self.out_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Input(shape=X.shape[-1]),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    MultiChannelWeightedDropout(y.shape[-1], p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_test = []\n",
    "fold_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multilabel_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 86ms/step\n",
      "Fold: 1 | Accuracy: 0.86452 | Train Time: 3.522820472717285 | Test Time: 0.11262083053588867\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 2 | Accuracy: 0.89032 | Train Time: 2.78016996383667 | Test Time: 0.03856062889099121\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Fold: 3 | Accuracy: 0.85806 | Train Time: 2.878084421157837 | Test Time: 0.03803873062133789\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Fold: 4 | Accuracy: 0.88667 | Train Time: 2.9217123985290527 | Test Time: 0.03904533386230469\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 5 | Accuracy: 0.88000 | Train Time: 2.9544618129730225 | Test Time: 0.037546396255493164\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 6 | Accuracy: 0.92000 | Train Time: 2.910968542098999 | Test Time: 0.03957223892211914\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Fold: 7 | Accuracy: 0.88667 | Train Time: 2.9549062252044678 | Test Time: 0.042440176010131836\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 8 | Accuracy: 0.84000 | Train Time: 2.9668500423431396 | Test Time: 0.037046194076538086\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 9 | Accuracy: 0.90000 | Train Time: 2.9199862480163574 | Test Time: 0.03899359703063965\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "Fold: 10 | Accuracy: 0.91333 | Train Time: 2.9519951343536377 | Test Time: 0.037302255630493164\n"
     ]
    }
   ],
   "source": [
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "    x_train, x_test, y_train, y_test = (X[train_idx]), (X[test_idx]), (y[train_idx]), (y[test_idx])\n",
    "    \n",
    "    train_init = time.time()\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "    train_time = time.time() - train_init\n",
    "\n",
    "    test_init = time.time()\n",
    "    prediction = model.predict(x_test)\n",
    "    test_time = time.time() - test_init\n",
    "\n",
    "    fold_test.append(y_test)\n",
    "    fold_pred.append(prediction)\n",
    "\n",
    "    preds = torch.tensor(prediction)\n",
    "    trues = torch.tensor(y_test)\n",
    "\n",
    "    print(f\"Fold: {fold+1} | Accuracy: {multilabel_accuracy(preds=preds, target=trues, num_labels=5, average='micro').item():.5f} | Train Time: {train_time} | Test Time: {test_time}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88396 | Precision: 0.19687 | Recall: 0.18210 | F1 Score: 0.18347 | AUC ROC: 0.77974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Program Files\\Anaconda\\envs\\py310\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional.classification import multilabel_accuracy, multilabel_precision, multilabel_recall, multilabel_f1_score, multilabel_auroc\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "auroc = []\n",
    "\n",
    "for i in range(10):\n",
    "    trues = torch.tensor(fold_test[i])\n",
    "    preds = torch.tensor(fold_pred[i])\n",
    "    accuracy.append(multilabel_accuracy(preds=preds, target=trues, num_labels=5).item())\n",
    "    precision.append(multilabel_precision(preds=preds, target=trues, num_labels=5).item())\n",
    "    recall.append(multilabel_recall(preds=preds, target=trues, num_labels=5).item())\n",
    "    f1_score.append(multilabel_f1_score(preds=preds, target=trues, num_labels=5).item())\n",
    "    auroc.append(multilabel_auroc(preds.float(), trues.long(), num_labels=5).item())\n",
    "\n",
    "print(f\"Accuracy: {np.mean(accuracy):.5f} | Precision: {np.mean(precision):.5f} | Recall: {np.mean(recall):.5f} | F1 Score: {np.mean(f1_score):.5f} | AUC ROC: {np.mean(auroc):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../Results/heart_disease_pred.pkl', 'wb') as file:\n",
    "    pickle.dump(fold_pred, file)\n",
    "with open(f'../Results/heart_disease_true.pkl', 'wb') as file:\n",
    "    pickle.dump(fold_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
